# -*- coding: utf-8 -*-
"""square_VS_circle_classifier.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1s_PoMudVnSZFrOhpo2sfYmlxuA-Wq4Rb
"""

# the import files
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D, BatchNormalization, Dropout
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.callbacks import ModelCheckpoint
from keras.models import load_model
from tensorflow.keras.preprocessing import image

import os
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

from keras_preprocessing.image import image_data_generator
#get data sets
# Get project files
!wget https://raw.githubusercontent.com/saswat711/Machine-Learning-Project/main/Square%20and%20Circle%20Classifier/dataset.zip

!unzip dataset.zip
PATH = ''

train_dir = os.path.join(PATH, 'toy_train')
validation_dir = os.path.join(PATH, 'toy_val')
test_dir = os.path.join(PATH, 'test')

# Get number of files in each directory. The train and validation directories
# each have the subdirecories "dogs" and "cats".
total_train = sum([len(files) for r, d, files in os.walk(train_dir)])
total_val = sum([len(files) for r, d, files in os.walk(validation_dir)])

# Variables for pre-processing and training.
batch_size = 32
epochs = 4
IMG_HEIGHT = 150
IMG_WIDTH = 150


#having the image generator
train_image_generator = ImageDataGenerator(
  rescale=1./255,
  dtype=tf.float32)

validation_image_generator =ImageDataGenerator(
  rescale=1./255,
  dtype=tf.float32)

test_image_generator = ImageDataGenerator(
    rescale = 1./255,
    dtype = tf.float32)

# CREATE THE DATA
train_data_gen = train_image_generator.flow_from_directory(
    directory=train_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    color_mode="rgb",
    batch_size=batch_size,
    class_mode="binary",
    shuffle=True,
    seed=42
)

val_data_gen = validation_image_generator.flow_from_directory(
    directory=validation_dir,
    target_size=(IMG_HEIGHT, IMG_WIDTH),
    color_mode="rgb",
    batch_size=batch_size,
    class_mode="binary",
    shuffle=False,
    seed=42
)

#plot images
#plot images
def plotImages(images_arr, probabilities = False):
    fig, axes = plt.subplots(len(images_arr), 1, figsize=(5,len(images_arr) * 3))
    if probabilities is False:
      for img, ax in zip( images_arr, axes):
          ax.imshow(img)
          ax.axis('off')
    else:
      for img, probability, ax in zip( images_arr, probabilities, axes):
          ax.imshow(img)
          ax.axis('off')
          if probability > 0.5:
              ax.set_title("%.2f" % (probability*100) + "% circle")
          else:
              ax.set_title("%.2f" % ((1-probability)*100) + "% rectangle")
    plt.show()

sample_training_images, _ = next(train_data_gen)
plotImages(sample_training_images[:5])


train_image_generator = ImageDataGenerator(rescale=1./255,
    rotation_range=90,
    width_shift_range=0.2,
    height_shift_range=0.2,
    shear_range=0.2,
    zoom_range=0.2,
    horizontal_flip=True,
    vertical_flip='nearest', 
    dtype=tf.float32)


# to plot train images with transformation
train_data_gen = train_image_generator.flow_from_directory(batch_size=batch_size,
                                                     directory=train_dir,
                                                     target_size=(IMG_HEIGHT, IMG_WIDTH),
                                                     class_mode='binary')

augmented_images = [train_data_gen[0][0][0] for i in range(5)]

plotImages(augmented_images)

# creating the model
model=Sequential()
model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)))
model.add(BatchNormalization())
model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D((2, 2)))
# model.add(Dropout(0.2))
model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(BatchNormalization())
model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D((2, 2)))
# model.add(Dropout(0.2))
model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(BatchNormalization())
model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))
model.add(BatchNormalization())
model.add(MaxPooling2D((2, 2)))
# model.add(Dropout(0.3))
model.add(Flatten())
model.add(Dense(1000, activation='relu', kernel_initializer='he_uniform'))
model.add(BatchNormalization())
model.add(Dropout(0.5))
model.add(Dense(100, activation='relu', kernel_initializer='he_uniform'))
model.add(BatchNormalization())
model.add(Dropout(0.3))
model.add(Dense(1, activation='sigmoid'))

print("Before compiling summary")
model.summary()

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

print("After compiling summary")
model.summary()

# to save in checkpoint the model
checkpoint = ModelCheckpoint( filepath='./', monitor='val_acc', verbose=1, save_best_only=True,
                              mode='auto', save_freq='epoch')
history = model.fit(train_data_gen, steps_per_epoch=len(train_data_gen), epochs=epochs, validation_data=val_data_gen, validation_steps= len(val_data_gen), callbacks=[checkpoint])

# TO SAVE THE MODEL
model.save('SQUARE_MODEL')

# to plot the accuracy
acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss = history.history['loss']
val_loss = history.history['val_loss']
epochs_range = range(len(acc))
plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)
plt.plot(epochs_range, acc,label='Training Accuracy')

plt.plot(epochs_range, val_acc, label='Validation Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Validation Accuracy')

plt.subplot(1, 2, 2)

plt.plot(epochs_range, loss, label='Training Loss')

plt.plot(epochs_range, val_loss, label='Validation Loss')
plt.legend(loc='upper right')
plt.title('Training and Validation Loss')
plt.show()

from google.colab import files
import cv2

# TO LOAD TEH MODEL
model = load_model('SQUARE_MODEL')

model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

#FUNCTION TO MAKE A PREDICTION USING MODEL
def pred_func():
  #to make preditction
  img_url  =  input("Enter the image url: ")
  !wget -O test_img "$img_url"
  img_path = "test_img"
  img = image.load_img(img_path, target_size=(IMG_WIDTH, IMG_HEIGHT))
  x = image.img_to_array(img)
  x = np.expand_dims(x, axis=0)
  x/=255.
  images = np.vstack([x])
  prediction = model.predict(images, batch_size=10)
  val = prediction[0][0]
  if(round(val)<=0.5):
        print("rectangle")
  else:
        print("circle")


pred_func()